{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "glob.glob(\"*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BL-Flickr-Images-Book.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['Edition Statement',\n",
    "           'Corporate Author',\n",
    "           'Corporate Contributors',\n",
    "           'Former owner',\n",
    "           'Engraver',\n",
    "           'Contributors',\n",
    "           'Issuance type',\n",
    "           'Shelfmarks']\n",
    "\n",
    "#Please drop the to_drop columns from dataframe\n",
    "#Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the index of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning columns using the `.apply` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "data_df = pd.DataFrame({\n",
    "    'column1': [1, 2, 3],\n",
    "    'column2': [4, 5, 6],\n",
    "    'column3': [7, 8, 9],\n",
    "    'column4': [10, 11, 12]\n",
    "})\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    # Example transformation: create a new value based on existing columns\n",
    "    # Your code:\n",
    "    \n",
    "    # Return the modified row\n",
    "    return row\n",
    "    \n",
    "# Apply the function to each row\n",
    "# Your code:\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "data_New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle BL-Flickr-Images-Book.csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title_to_string = df.Title.to_list()\n",
    "Ut = Title_to_string[:10]\n",
    "Ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Title\n",
    "'`Walter Forbes.` [A novel.] By A. A',\n",
    "\n",
    " '`All for Greed.` [A novel. The dedication signed: A. A. A., i.e. Marie Pauline Rose, Baroness Blaze de Bury.]',\n",
    " \n",
    " '`Love the Avenger`. By the author of “All for Greed.” [The dedication signed: A. A. A., i.e. Marie Pauline Rose, Baroness Blaze de Bury.]',\n",
    " \n",
    " '`Welsh Sketches, chiefly ecclesiastical, to the close of the twelfth century`. By the author of “Proposals for Christian Union” (E. S. A. [i.e. Ernest Appleyard])',\n",
    " \n",
    " '[`The World in which I live, and my place in it.` By E. S. A. [i.e. Letitia Willgoss Stone.] Edited by ... J. H. Broome.]',\n",
    " \n",
    " '[`The World in which I live, and my place in it.` By E. S. A. [i.e. Letitia Willgoss Stone.] Edited by ... J. H. Broome.]',\n",
    " \n",
    " '`Lagonells.` By the author of Darmayne (F. E. A. [i.e. Florence Emily Ashley])',\n",
    " \n",
    " '`The Coming of Spring, and other poems.` By J. A. [i.e. J. Andrews.]',\n",
    " \n",
    " '`A Warning to the inhabitants of England, and London in particular ... ` By M. A. [i.e. Mary Adams.]',\n",
    " \n",
    " '`A Satyr against Vertue. (A poem: supposed to be spoken by a Town-Hector. `[By John Oldham. The preface signed: T. A.])'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please clean up the book title and save the results to a new dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title):\n",
    "    \n",
    "    if title == 'nan':\n",
    "        return 'NaN'\n",
    "    \n",
    "    if title[0] == '[':\n",
    "        title = title[1: title.find(']')]\n",
    "        \n",
    "    if 'by' in title:\n",
    "        title = title[:title.find('by')]\n",
    "    elif 'By' in title:\n",
    "        title = title[:title.find('By')]\n",
    "        \n",
    "    if '[' in title:\n",
    "        title = title[:title.find('[')]\n",
    "\n",
    "    return title\n",
    "\n",
    "#Get the clean title\n",
    "df['Title'] = df['Title'].apply(clean_title)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `.str`,  `np.where` methods to clean columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.where(condition, [x, y, ]/)\n",
    "When only condition is provided, this function is a shorthand for np.asarray(condition).nonzero(). Using nonzero directly should be preferred, as it behaves correctly for subclasses. The rest of this documentation covers only the case where all three arguments are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(a < 5, a, 10*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4157862 and 4159587\n",
    "df['Place of Publication'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = df['Place of Publication']\n",
    "df['Place of Publication'] = np.where(pub.str.contains('London'), 'London',df['Place of Publication'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns and skipping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df = pd.read_csv('olympics_part1.csv')\n",
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_part1_df = pd.read_csv('olympics_part1.csv', skiprows = 1, header = 0)\n",
    "olympics_part1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names =  {'Unnamed: 0': 'Country',\n",
    "              '? Summer': 'Summer Olympics',\n",
    "              '01 !': 'Gold',\n",
    "              '02 !': 'Silver',\n",
    "              '03 !': 'Bronze', }\n",
    "olympics_part1_df.rename(columns = new_names, inplace = True)\n",
    "olympics_part1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_part2_df = pd.read_csv('olympics_part2.csv', skiprows = 1, header = 0)\n",
    "olympics_part2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_part2_df.rename(columns = new_names, inplace = True)\n",
    "olympics_part2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_part1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_part2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to merge to dataframe via .merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "olympics_part1_df.merge(olympics_part2_df,left_on='Country')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat([olympics_part1_df, olympics_part2_df])\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.reset_index(drop=True, inplace = True)\n",
    "newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df = pd.read_csv('olympics_part3.csv')\n",
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_part3_df = pd.read_csv('olympics_part3.csv', skiprows = 1, header = 0)\n",
    "olympics_part3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names_2 =  {'Unnamed: 0': 'Country',\n",
    "              '? Winter': 'Winter Olympics',\n",
    "              '01 !': 'Gold.1',\n",
    "              '02 !': 'Silver.1',\n",
    "              '03 !': 'Bronze.1',\n",
    "              'Total': 'Total.1',\n",
    "              '? Games': '# Games', \n",
    "              '01 !.1': 'Gold.2',\n",
    "              '02 !.1': 'Silver.2',\n",
    "              '03 !.1': 'Bronze.2'}\n",
    "\n",
    "olympics_part3_df.rename(columns = new_names_2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_part3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for .join()\n",
    "#### DataFrame.join() is a convenient method for combining the columns of two potentially differently-indexed DataFrames into a single result DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for .merge()\n",
    "#### DataFrame.merge() is a method for combining the columns of two DataFrames that may have partially identical indexes into a single resulting DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In class Practice: \n",
    "1. Please use .merge or .join combine olympics data part1, part2, part3\n",
    "2. Calculate the total number of accumulated medals of Summer and Winter Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to CSV\n",
    "Please save the complete dataframe to a .csv file and upload your results to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
