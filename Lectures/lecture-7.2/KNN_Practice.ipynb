{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# K-Nearest Neighbors (K-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvGPUQaHhXfL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1VMqkGvhc3-"
   },
   "source": [
    "## 1. Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M52QDmyzhh9s"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "oR3b6w66JmXl",
    "outputId": "563f8fc8-3263-4785-a379-50fcc91c8279"
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvxIPVyMhmKp"
   },
   "source": [
    "### 1.1 Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVzJWAXIhxoC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3nS3-6r1i2B",
    "outputId": "04a4e0c2-1e3e-4657-dfe3-b7383de51552",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dpDLojm1mVG",
    "outputId": "3d7328c6-a6bb-4e48-e00d-7226e1c65b0e"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbb7i0DH1qui",
    "outputId": "49d74338-157e-4d0a-9547-7eb2213071c3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kj1hnFAR1s5w"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW3c7UYih0hT"
   },
   "source": [
    "### 1.2 Feature Scaling\n",
    "\n",
    "Standardizing data using [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) is important because many machine learning algorithms perform better or converge faster when features are on a similar scale. This process, which involves scaling features to have zero mean and unit variance, helps in reducing the bias that can be introduced by features with larger scales and improves the overall predictive performance of models, especially those sensitive to feature scaling like Support Vector Machines and k-Nearest Neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.fit(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z = (x-u) /s , u (mean) = 0.5, s (standard deviation ) = 0.5\n",
    "\n",
    "Z_new = (2-0.5)/0.5 = 1.5/0.5 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform([[2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Back to Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fQlDPKCh8sc"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test) #avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syrnD1Op2BSR",
    "outputId": "1ec8f877-913c-453a-f48d-5fd18d8e78c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUd6iBRp2C3L",
    "outputId": "ae051ec0-0d1b-45e9-b9b3-ee4b85a09e57"
   },
   "outputs": [],
   "source": [
    "X_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb6jCOCQiAmP"
   },
   "source": [
    "## 2. Training the K-NN model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PkdE-i4-vY0"
   },
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self,k):\n",
    "        self.k=k\n",
    "        print('Input k value: ',self.k)\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        self.x_train=X_train\n",
    "        self.y_train=y_train\n",
    "    \n",
    "    def calculate_euclidean(self,sample1,sample2):\n",
    "        distance=0.0\n",
    "        for i in range(len(sample1)):\n",
    "            #Euclidean Distance = sqrt(sum i to N (x1_i ‚Äì x2_i)^2)\n",
    "            distance+=(sample1[i]-sample2[i])**2 \n",
    "        return np.sqrt(distance)\n",
    "\n",
    "    def nearest_neighbors(self, test_sample):\n",
    "        distances = []  # List to store distances from the test sample to each training sample\n",
    "\n",
    "        # Loop over each sample in the training set\n",
    "        for i in range(len(self.x_train)):\n",
    "            # Calculate the Euclidean distance from the current training sample to the test sample\n",
    "            # Append a tuple of (training label, distance) to the distances list\n",
    "            distances.append((self.y_train[i], self.calculate_euclidean(self.x_train[i], test_sample)))\n",
    "\n",
    "        # Sort the distances list in ascending order based on the distance\n",
    "        distances.sort(key=lambda x: x[1])\n",
    "\n",
    "        neighbors = []  # List to store the nearest neighbors\n",
    "\n",
    "        # Retrieve the first 'k' nearest neighbors\n",
    "        for i in range(self.k):\n",
    "            # Append the label of each neighbor to the neighbors list\n",
    "            neighbors.append(distances[i][0])\n",
    "\n",
    "        # Return the list of nearest neighbors\n",
    "        return neighbors\n",
    "\n",
    "    def predict(self, test_set):\n",
    "        predictions = []  # List to store predictions for each test sample\n",
    "\n",
    "        # Loop over each sample in the test set\n",
    "        for test_sample in test_set:\n",
    "            # Find the nearest neighbors for the current test sample\n",
    "            neighbors = self.nearest_neighbors(test_sample)\n",
    "\n",
    "            # Extract the labels of the nearest neighbors\n",
    "            labels = [sample for sample in neighbors]\n",
    "\n",
    "            # Determine the most common label among the neighbors\n",
    "            prediction = max(labels, key=labels.count)\n",
    "\n",
    "            # Append the predicted label to the predictions list\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # Return the list of predictions for the test set\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sx7G6PLd-xzd",
    "outputId": "40a9ebe5-e6e7-4740-9209-9f5106e2013d"
   },
   "outputs": [],
   "source": [
    "model=KNN(5) #our model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKYVQH-l5NpE"
   },
   "source": [
    "### 2.1 Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQOlUC3sA2sB"
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)#our model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OMC_P0diaoD"
   },
   "source": [
    "## 2.3 Visualising the Test set results and add your name to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#'sc' is your StandardScaler and 'X_test' is your scaled test dataset\n",
    "X_set, y_set = sc.inverse_transform(X_test), y_test\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot True labels\n",
    "plt.scatter(X_set[:, 0], X_set[:, 1], c=y_test, cmap='viridis', edgecolor='k', s=20)\n",
    "plt.title(\"<Your name>+True Labels\")\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#'sc' is your StandardScaler and 'X_test' is your scaled test dataset\n",
    "X_set, y_set = sc.inverse_transform(X_test), predictions\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot True labels using original values\n",
    "plt.scatter(X_set[:, 0], X_set[:, 1], c=predictions, cmap='viridis', edgecolor='k', s=20)\n",
    "plt.title(\"<Your name>+ KNN Predicted Labels\")\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The scikit-learn approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Initialize the KNN classifier with k=5\n",
    "\n",
    "knn = #your code\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please visualize the results and add your name to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot true labels\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='viridis', edgecolor='k', s=20)\n",
    "plt.title(\"<Your Name>+True Labels\")\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "\n",
    "# Plot predicted labels\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap='viridis', edgecolor='k', s=20)\n",
    "plt.title(\"<Your Name>+ KNN Predicted Labels\")\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ù Practice Lab: K-Nearest Neighbors (KNN)\n",
    "\n",
    "### üß† Objective\n",
    "In this exercise, you will:\n",
    "1. Build a simple KNN classifier.  \n",
    "2. Predict class labels for new data points.  \n",
    "3. Visualize decision boundaries and understand the role of **K**.  \n",
    "\n",
    "---\n",
    "## üß© Scenario\n",
    "\n",
    "A teacher collected data about students‚Äô **study hours** and **sleep hours**, along with whether they **passed** an exam.\n",
    "\n",
    "| Student | Study_Hours | Sleep_Hours | Pass |\n",
    "|----------|--------------|-------------|------|\n",
    "| A | 2 | 9 | No |\n",
    "| B | 3 | 8 | No |\n",
    "| C | 4 | 7 | No |\n",
    "| D | 6 | 6 | Yes |\n",
    "| E | 7 | 5 | Yes |\n",
    "| F | 8 | 4 | Yes |\n",
    "| G | 9 | 3 | Yes |\n",
    "\n",
    "You will use KNN to predict whether a new student is likely to **pass** based on their study and sleep hours.\n",
    "\n",
    "---\n",
    "## üß† Task Requirements\n",
    "\n",
    "1. Create a small dataset as a pandas DataFrame.  \n",
    "2. Split it into features (`Study_Hours`, `Sleep_Hours`) and labels (`Pass`).  \n",
    "3. Train a **KNN classifier** using `KNeighborsClassifier` from scikit-learn.  \n",
    "4. Predict the outcome for a new student (e.g., `Study_Hours=5`, `Sleep_Hours=6`).  \n",
    "5. Try different values of **K** (e.g., 1, 3, 5) and compare results.  \n",
    "6. Visualize the data points with color-coded classes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    " \n",
    "data = {\n",
    "    'Study_Hours': [2,3,4,6,7,8,9],\n",
    "    'Sleep_Hours': [9,8,7,6,5,4,3],\n",
    "    'Pass': ['No','No','No','Yes','Yes','Yes','Yes']\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "k_nearest_neighbors_from_scratch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
