{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fedb103",
   "metadata": {},
   "source": [
    "# Read Damaged Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06353432",
   "metadata": {},
   "source": [
    "Data interpretation varies with format, necessitating organization into dataframes for machine readability. This step transforms diverse data into a structured, table-like format, facilitating manipulation and analysis. It's crucial for identifying trends and ensuring data quality, thus setting the foundation for subsequent analytical and predictive tasks in a unified, efficient manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "csvfiles = glob.glob(\"*.csv\")\n",
    "csvfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89bc6bd",
   "metadata": {},
   "source": [
    "## 1.1 Read CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f7891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'us_tourism.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "dataframe_csv1 = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "dataframe_csv1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5824bbd",
   "metadata": {},
   "source": [
    "## 1.2 Handle damaged csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c9ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path2 = 'us_tourism2damage.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "\n",
    "df = pd.read_csv(file_path2)\n",
    "\n",
    "# # Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e6af4",
   "metadata": {},
   "source": [
    "### Cannot read damage file by pandas\n",
    "\n",
    "We need to read file line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "file_path = 'us_tourism2damage.csv'\n",
    "\n",
    "#read line by line, and filter the bad data\n",
    "a = 0\n",
    "title = []\n",
    "gooddata = []\n",
    "baddata= []\n",
    "\n",
    "# Your code:\n",
    "with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        if a == 0:\n",
    "            title = row\n",
    "        a += 1\n",
    "        if len(row) == 8 and a != 1:\n",
    "            gooddata.append(row)\n",
    "        else:\n",
    "            baddata.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fc8cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gooddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61f65d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gooddf = pd.DataFrame(gooddata,columns = title)\n",
    "gooddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff3487",
   "metadata": {},
   "source": [
    "## 2.1 Read json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab55147",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfiles = glob.glob(\"*.json\")\n",
    "jsonfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the JSON file\n",
    "df = pd.read_json(jsonfiles[2],lines = True)\n",
    "\n",
    "# Displaying the DataFrame\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff3241",
   "metadata": {},
   "source": [
    "## 2.2 Handle damaged json Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304e065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading the JSON file\n",
    "dfDamage = pd.read_json(jsonfiles[0],lines = True)\n",
    "\n",
    "# Displaying the DataFrame\n",
    "dfDamage.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d97a6",
   "metadata": {},
   "source": [
    "### 2.2.1 Simple demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107af1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example JSON data as a list of strings (each string is a JSON object)\n",
    "json_data = [\n",
    "    '{\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"}',\n",
    "    '{\"name\": \"Bob\", \"age\": 30, \"city\": \"San Francisco\"}',\n",
    "    '{\"name\": \"Charlie\", \"age\": 35}',\n",
    "    '{\"name\": \"Bib\", \"age\": , \"city\": \"Seattle\"}',\n",
    "    '{\"name\": \"Bcob\", \"city\": \"Beijing\"}',\n",
    "    '{\"name\": \"Bob\", \"xxxx\": 30, \"city\": \"San Francisco\"}'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for json_str in json_data:\n",
    "    try:\n",
    "        # Attempt to parse each line as JSON\n",
    "        json_obj = json.loads(json_str)\n",
    "\n",
    "        # Handle missing or extra data\n",
    "        if 'name' not in json_obj:\n",
    "            json_obj['name'] = None\n",
    "        if 'age' not in json_obj:\n",
    "            json_obj['age'] = None\n",
    "        if 'city' not in json_obj:\n",
    "            json_obj['city'] = None\n",
    "\n",
    "        # Append the valid JSON object to the list\n",
    "        data.append(json_obj)\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        print(f'Invalid Json data')\n",
    "\n",
    "# data\n",
    "# Convert the list of dictionaries to a pandas DataFrame (optional)\n",
    "dfjson= pd.DataFrame(data)\n",
    "\n",
    "#print\n",
    "dfjson[['name','age','city']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89447692",
   "metadata": {},
   "source": [
    "### 2.2.3 Handle the damaged json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa0bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = 'damaged.json'  # Replace with your file path\n",
    "data = []\n",
    "title = ['Region', 'State', 'Attraction', 'Description', \n",
    " 'Food Specialty', 'Food Description', 'Best Time to Visit', 'Notable Events']\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Parse the JSON string\n",
    "            json_obj = json.loads(line)\n",
    "\n",
    "            # Handle missing data by setting a default value\n",
    "            # Your code\n",
    "            for key in title:\n",
    "                if key not in json_obj:\n",
    "                    json_obj[key] = None\n",
    "                \n",
    "            \n",
    "            # Append the processed JSON object to the list\n",
    "            data.append(json_obj)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f'Invalid Json data: {line}')\n",
    "            \n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame (optional)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e322695",
   "metadata": {},
   "source": [
    "## 3.1 Read Txt data\n",
    "\n",
    "Examples for **\"split\"**\n",
    "```python\n",
    "text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 'Region: Northeast State: New York'\n",
    "result_h = h.split(\" \")\n",
    "result_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de030f89-03d9-4409-a1fa-a51690c6984f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = 'unstructureddata.txt'  # use your file path\n",
    "\n",
    "# Function to process a block of text and return a dictionary\n",
    "def process_block(block):\n",
    "    entity = {}\n",
    "    for item in block: \n",
    "        key, value = item.split(\":\")\n",
    "        entity[key] = value\n",
    "    return entity\n",
    "\n",
    "# Read and process the file\n",
    "current_data= []\n",
    "result= []\n",
    "with open(file_path,'r') as file:\n",
    "    for line in file:\n",
    "        # Your code\n",
    "        if line.strip() == \"\":\n",
    "            dfcontent = process_block(current_data)\n",
    "            result.append(dfcontent)\n",
    "            current_data = []\n",
    "        else:\n",
    "            current_data.append(line.strip())\n",
    "            \n",
    "print(result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c001d-baaf-416e-9417-a0be1a7d20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the list of dictionaries into a DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "# # Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3833f14",
   "metadata": {},
   "source": [
    "## 3.2 Handle damaged txt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b090bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Your turn -- Class practice\"\"\"\n",
    "file_path = 'damaged_data.txt'  # use your file path\n",
    "\n",
    "# Define the expected keys\n",
    "expected_keys = [\"Region\", \"State\", \"Attraction\", \"Description\", \n",
    "                 \"Food Specialty\", \"Food Description\", \n",
    "                 \"Best Time to Visit\", \"Notable Events\"]\n",
    "\n",
    "\n",
    "# Function to process a block of text and return a dictionary\n",
    "def process_block_with_damaged(block):\n",
    "    entity = {key: None for key in expected_keys}\n",
    "    #Your code:\n",
    "    for item in block:\n",
    "        if \": \" in item:\n",
    "            key, value = item.split(\": \")\n",
    "            if key in entity:\n",
    "                entity[key] = value\n",
    "    \n",
    "    return entity\n",
    "\n",
    "# Read and process the file\n",
    "current_data= []\n",
    "result= []\n",
    "with open(file_path,'r') as file:\n",
    "    for line in file:\n",
    "        # Your code:\n",
    "        if line.strip() == \"\":\n",
    "            processed_data = process_block_with_damaged(current_data)\n",
    "            result.append(processed_data)\n",
    "            current_data = []\n",
    "        else:\n",
    "            current_data.append(line.strip())\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "dfnew = pd.DataFrame(result)\n",
    "\n",
    "# Display the DataFrame\n",
    "dfnew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582dc81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38f27c02-ecb9-4c4e-b92e-7688f81e03e9",
   "metadata": {},
   "source": [
    "### Practice 🧪 Lab: Cleaning “Damaged” Data with pandas\n",
    "\n",
    "In this practice, you’ll practice detecting and fixing common data problems:\n",
    "\n",
    "- Rows with **missing fields**\n",
    "- Rows with **extra fields** (e.g., too many columns due to extra commas)\n",
    "- **Wrong types** (strings in numeric columns)\n",
    "- **Out-of-range values** (e.g., impossible GPA)\n",
    "- Empty strings vs true missing values (`NaN`)\n",
    "\n",
    "You will:  \n",
    "1) Load a deliberately “damaged” CSV,  \n",
    "2) Identify & filter bad rows,  \n",
    "3) Coerce types, and  \n",
    "4) Produce a clean DataFrame ready for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49362fd-70c9-4189-baf3-a3c80c3556c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚧 Create a deliberately “damaged” CSV (run this cell once)\n",
    "source_csv = \"\"\"Student_ID,Name,Major,Credits,GPA,Grad_Year\n",
    "1001,Alice,Computer Science,120,3.85,2026\n",
    "1002,Bob,Math, ,3.10,2025\n",
    "1003,Charlie,Physics,98,3O,2024\n",
    "1004,Diana,Economics,140,4.7,2023\n",
    "1005,Ed,Computer Science,129,N/A,2027\n",
    "1006, ,Biology,88,2.95,2028\n",
    "1007,Grace,Physics,101,3.40,2029,EXTRA_TOKEN\n",
    ",Henry,Math,64,2.70,2026\n",
    "1009,Ivy,,110,3.20,2025\n",
    "1010,Jack,Economics,215,3.50,2035\n",
    "1011,Kate,Chemistry,95,3.00,\n",
    "1012,Liam,Computer Science,NaN,3.60,2024\n",
    "1013,Mia,Math,77,,2025\n",
    "1014,Noah,Physics,85,3.25,2027\n",
    "1015,Olivia,Economics,,2.80,2026\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752a9f9-7167-4a9f-aceb-7d1022684c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote damaged CSV to: damaged_studesnts.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = \"damaged_students.csv\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(source_csv)\n",
    "print(f\"Wrote damaged CSV to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defab7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "file_path = 'damaged_students.csv'\n",
    "\n",
    "index = 0\n",
    "title = []\n",
    "good_data = []\n",
    "bad_data = []\n",
    "\n",
    "with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        if index == 0:\n",
    "            title = row\n",
    "        index += 1\n",
    "        if len(row) == 6 and index != 1:\n",
    "            good_data.append(row)\n",
    "        else:\n",
    "            bad_data.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65662356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Major</th>\n",
       "      <th>Credits</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Grad_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>120</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Math</td>\n",
       "      <td></td>\n",
       "      <td>3.10</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>Physics</td>\n",
       "      <td>98</td>\n",
       "      <td>3O</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Diana</td>\n",
       "      <td>Economics</td>\n",
       "      <td>140</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Ed</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>129</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1006</td>\n",
       "      <td></td>\n",
       "      <td>Biology</td>\n",
       "      <td>88</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Henry</td>\n",
       "      <td>Math</td>\n",
       "      <td>64</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1009</td>\n",
       "      <td>Ivy</td>\n",
       "      <td></td>\n",
       "      <td>110</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1010</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Economics</td>\n",
       "      <td>215</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1011</td>\n",
       "      <td>Kate</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>95</td>\n",
       "      <td>3.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1012</td>\n",
       "      <td>Liam</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1013</td>\n",
       "      <td>Mia</td>\n",
       "      <td>Math</td>\n",
       "      <td>77</td>\n",
       "      <td></td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1014</td>\n",
       "      <td>Noah</td>\n",
       "      <td>Physics</td>\n",
       "      <td>85</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1015</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>Economics</td>\n",
       "      <td></td>\n",
       "      <td>2.80</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student_ID     Name             Major Credits   GPA Grad_Year\n",
       "0        1001    Alice  Computer Science     120  3.85      2026\n",
       "1        1002      Bob              Math          3.10      2025\n",
       "2        1003  Charlie           Physics      98    3O      2024\n",
       "3        1004    Diana         Economics     140   4.7      2023\n",
       "4        1005       Ed  Computer Science     129   N/A      2027\n",
       "5        1006                    Biology      88  2.95      2028\n",
       "6                Henry              Math      64  2.70      2026\n",
       "7        1009      Ivy                       110  3.20      2025\n",
       "8        1010     Jack         Economics     215  3.50      2035\n",
       "9        1011     Kate         Chemistry      95  3.00          \n",
       "10       1012     Liam  Computer Science     NaN  3.60      2024\n",
       "11       1013      Mia              Math      77            2025\n",
       "12       1014     Noah           Physics      85  3.25      2027\n",
       "13       1015   Olivia         Economics          2.80      2026"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gooddf = pd.DataFrame(good_data,columns = title)\n",
    "gooddf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
